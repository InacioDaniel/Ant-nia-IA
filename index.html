<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ant√≠nia IA - by @inacio.u.daniel</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { background-color: #0f172a; color: white; font-family: 'Inter', sans-serif; }
        .chat-container { height: calc(100vh - 160px); overflow-y: auto; }
        .glass { background: rgba(255, 255, 255, 0.05); backdrop-filter: blur(10px); border: 1px solid rgba(255,255,255,0.1); }
        .user-msg { background: #3b82f6; align-self: flex-end; }
        .ai-msg { background: #1e293b; align-self: flex-start; }
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-thumb { background: #334155; border-radius: 10px; }
    </style>
</head>
<body class="p-4 md:p-8">

    <div class="max-w-4xl mx-auto flex flex-col h-full">
        <header class="mb-6 flex justify-between items-center">
            <div>
                <h1 class="text-3xl font-bold text-blue-400">Ant√≠nia IA</h1>
                <p class="text-xs text-gray-400">Processamento Local & exige capacidade local</p>
            </div>
            <div id="status" class="text-xs bg-yellow-900/30 text-yellow-500 px-3 py-1 rounded-full border border-yellow-700">
                Aguardando comando...
            </div>
        </header>

        <div id="chatBox" class="chat-container glass rounded-2xl p-4 flex flex-col gap-4 mb-4">
            <div class="ai-msg p-3 rounded-xl max-w-[80%]">
                Ol√°! Eu sou a **Ant√≠nia**. Posso analisar imagens, tentar gerar v√≠deos curtos e conversar. Como n√£o uso chaves de API, utilizo recursos do seu navegador!
            </div>
        </div>

        <div id="imagePreview" class="hidden mb-2 p-2 glass rounded-lg w-32 relative">
            <img src="" id="previewImg" class="rounded">
            <button onclick="clearImage()" class="absolute -top-2 -right-2 bg-red-500 rounded-full w-5 h-5 text-xs">‚úï</button>
        </div>

        <div class="glass p-4 rounded-2xl flex flex-col gap-2">
            <div class="flex items-center gap-2">
                <input type="file" id="fileInput" accept="image/*" class="hidden" onchange="handleImage(this)">
                <button onclick="document.getElementById('fileInput').click()" class="p-2 hover:bg-white/10 rounded-lg transition" title="Analisar Imagem">
                    üñºÔ∏è
                </button>
                <input type="text" id="userInput" placeholder="Pergunte algo ou pe√ßa um v√≠deo (ex: 'Gere um v√≠deo de gato')..." 
                       class="flex-1 bg-transparent border-none outline-none text-white p-2">
                <button onclick="sendMessage()" class="bg-blue-600 hover:bg-blue-500 px-6 py-2 rounded-xl font-bold transition">
                    Enviar
                </button>
            </div>
        </div>
    </div>

<script>
        const chatBox = document.getElementById('chatBox');
        const userInput = document.getElementById('userInput');
        const status = document.getElementById('status');
        let selectedImage = null;
        let conversationHistory = [];

        // Fun√ß√£o para adicionar mensagens ao chat
        function addMessage(content, isUser = false) {
            const div = document.createElement('div');
            div.className = `${isUser ? 'user-msg' : 'ai-msg'} p-3 rounded-xl max-w-[80%] animate-fade-in`;
            div.innerHTML = content;
            chatBox.appendChild(div);
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        // Processamento de Imagem
        function handleImage(input) {
            if (input.files && input.files[0]) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    document.getElementById('imagePreview').classList.remove('hidden');
                    document.getElementById('previewImg').src = e.target.result;
                    selectedImage = e.target.result;
                }
                reader.readAsDataURL(input.files[0]);
            }
        }

        function clearImage() {
            selectedImage = null;
            document.getElementById('imagePreview').classList.add('hidden');
            document.getElementById('fileInput').value = '';
        }

        // API 1: Hugging Face Inference API (Sem token para modelos p√∫blicos)
        async function callHuggingFace(text) {
            try {
                const response = await fetch("https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium", {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ inputs: text })
                });
                const data = await response.json();
                return data[0]?.generated_text || data.generated_text || null;
            } catch (e) {
                console.error("HuggingFace error:", e);
                return null;
            }
        }

        // API 2: DuckDuckGo Instant Answer (Para perguntas factuais)
        async function searchDuckDuckGo(query) {
            try {
                const response = await fetch(`https://api.duckduckgo.com/?q=${encodeURIComponent(query)}&format=json&no_html=1&skip_disambig=1`);
                const data = await response.json();
                return data.AbstractText || data.Answer || null;
            } catch (e) {
                console.error("DuckDuckGo error:", e);
                return null;
            }
        }

        // API 3: Wikipedia API (Para conhecimento geral)
        async function searchWikipedia(query) {
            try {
                const response = await fetch(`https://pt.wikipedia.org/api/rest_v1/page/summary/${encodeURIComponent(query)}`);
                const data = await response.json();
                return data.extract || null;
            } catch (e) {
                console.error("Wikipedia error:", e);
                return null;
            }
        }

        // API 4: An√°lise de Sentimento usando modelo de classifica√ß√£o
        async function analyzeSentiment(text) {
            try {
                const response = await fetch("https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment", {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ inputs: text })
                });
                const data = await response.json();
                return data[0] || null;
            } catch (e) {
                return null;
            }
        }

        // API 5: Tradu√ß√£o autom√°tica
        async function translateText(text, targetLang = "pt") {
            try {
                const response = await fetch(`https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=${targetLang}&dt=t&q=${encodeURIComponent(text)}`);
                const data = await response.json();
                return data[0]?.[0]?.[0] || null;
            } catch (e) {
                return null;
            }
        }

        // L√≥gica Principal de Resposta Inteligente
        async function sendMessage() {
            const text = userInput.value.trim();
            if (!text && !selectedImage) return;

            addMessage(text || "Analisando esta imagem...", true);
            userInput.value = '';
            status.innerText = "Ant√≠nia est√° pensando...";
            status.className = "text-xs bg-blue-900/30 text-blue-400 px-3 py-1 rounded-full border border-blue-600";

            try {
                if (selectedImage) {
                    await analyzeImageReal();
                } else if (text.toLowerCase().includes("traduz") || text.toLowerCase().includes("translate")) {
                    await handleTranslation(text);
                } else if (text.toLowerCase().includes("sentimento") || text.toLowerCase().includes("emo√ß√£o")) {
                    await handleSentiment(text);
                } else {
                    await respondIntelligent(text);
                }
            } catch (e) {
                addMessage("‚ùå Desculpe, ocorreu um erro. Tente novamente.");
                console.error(e);
            }

            status.innerText = "Pronta";
            status.className = "text-xs bg-green-900/30 text-green-400 px-3 py-1 rounded-full border border-green-600";
        }

        // Resposta Inteligente com m√∫ltiplas APIs
        async function respondIntelligent(query) {
            conversationHistory.push(query);

            // Tentar DuckDuckGo primeiro para respostas r√°pidas
            const ddgAnswer = await searchDuckDuckGo(query);
            if (ddgAnswer && ddgAnswer.length > 20) {
                addMessage(`üìö **Informa√ß√£o:** ${ddgAnswer}`);
                return;
            }

            // Tentar Wikipedia para conhecimento geral
            const wikiAnswer = await searchWikipedia(query);
            if (wikiAnswer && wikiAnswer.length > 30) {
                addMessage(`üìñ **Da Wikipedia:** ${wikiAnswer}`);
                return;
            }

            // Usar modelo de linguagem como fallback
            const aiAnswer = await callHuggingFace(query);
            if (aiAnswer) {
                addMessage(`ü§ñ ${aiAnswer}`);
                return;
            }

            // Resposta padr√£o se tudo falhar
            addMessage(`Entendi sua pergunta sobre "${query}". Posso ajudar de outras formas: an√°lise de sentimento, tradu√ß√£o, ou busca de informa√ß√µes espec√≠ficas!`);
        }

        // An√°lise de Imagem Real usando Vision API
        async function analyzeImageReal() {
            addMessage("üîç Analisando imagem com IA...");
            
            try {
                // Usando API de vis√£o computacional do Hugging Face
                const blob = await fetch(selectedImage).then(r => r.blob());
                const response = await fetch("https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-base", {
                    method: "POST",
                    body: blob
                });
                const data = await response.json();
                
                if (data[0]?.generated_text) {
                    addMessage(`üñºÔ∏è **An√°lise da Imagem:** ${data[0].generated_text}`);
                } else {
                    addMessage("üñºÔ∏è Identifiquei elementos visuais interessantes na imagem, mas n√£o consegui gerar uma descri√ß√£o detalhada.");
                }
            } catch (e) {
                addMessage("‚ö†Ô∏è N√£o foi poss√≠vel analisar a imagem no momento. O modelo pode estar carregando.");
            }
            
            clearImage();
        }

        // An√°lise de Sentimento
        async function handleSentiment(text) {
            const textToAnalyze = text.replace(/sentimento|emo√ß√£o|analise/gi, '').trim();
            const sentiment = await analyzeSentiment(textToAnalyze);
            
            if (sentiment) {
                const topSentiment = sentiment.reduce((a, b) => a.score > b.score ? a : b);
                const emoji = topSentiment.label === 'POSITIVE' ? 'üòä' : topSentiment.label === 'NEGATIVE' ? 'üòî' : 'üòê';
                addMessage(`${emoji} **An√°lise de Sentimento:** ${topSentiment.label} (${(topSentiment.score * 100).toFixed(1)}% de confian√ßa)`);
            } else {
                addMessage("N√£o foi poss√≠vel analisar o sentimento no momento.");
            }
        }

        // Tradu√ß√£o
        async function handleTranslation(text) {
            const textToTranslate = text.replace(/traduz|translate/gi, '').trim();
            const translated = await translateText(textToTranslate);
            
            if (translated) {
                addMessage(`üåê **Tradu√ß√£o:** ${translated}`);
            } else {
                addMessage("N√£o foi poss√≠vel traduzir no momento.");
            }
        }

        // Enviar com Enter
        userInput.addEventListener('keypress', (e) => { if(e.key === 'Enter') sendMessage(); });
    </script>
</body>
</html>

